{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Chain Types: A Comprehensive Comparison\n",
    "\n",
    "LangChain provides several `chain_type` strategies to process, summarize, and interact with multiple documents to achieve various tasks like summarization, question answering, and more. Below is a detailed comparison of the common chain types used in LangChain.\n",
    "\n",
    "## 1. Map-Reduce\n",
    "The `map-reduce` approach is a well-known distributed data processing strategy that has been adapted for language model tasks involving multiple documents or large data.\n",
    "\n",
    "- **How It Works**:\n",
    "  - **Map Phase**: Each document is independently processed to generate an intermediate result. For example, the model answers a question or creates a summary for each document separately.\n",
    "  - **Reduce Phase**: The results from the map phase are then aggregated or summarized to create a final answer.\n",
    "\n",
    "- **Pros**:\n",
    "  - **Scalability**: It can process large volumes of documents since each document is handled independently. This makes it well-suited for large-scale datasets.\n",
    "  - **Parallel Processing**: The mapping phase can be parallelized, making it efficient for handling many documents.\n",
    "\n",
    "- **Cons**:\n",
    "  - **Context Loss**: Since each document is processed in isolation, there may be a lack of overall context or coherence when aggregating results.\n",
    "  - **Reduce Complexity**: The reduce step must be well-defined to merge diverse responses effectively, which can be challenging for complex questions.\n",
    "\n",
    "- **Best Use Cases**:\n",
    "  - Summarizing a large number of documents.\n",
    "  - Question answering from a broad set of documents.\n",
    "\n",
    "## 2. Refine\n",
    "The `refine` chain type is an iterative method that refines the output by taking the previous answer and adding to it with the context from each subsequent document.\n",
    "\n",
    "- **How It Works**:\n",
    "  - The first document is processed to generate an initial answer.\n",
    "  - Each subsequent document is used to refine the previous answer, incorporating additional context and modifying the response iteratively.\n",
    "\n",
    "- **Pros**:\n",
    "  - **Comprehensive Context**: Since each document is used to iteratively improve the answer, it ensures that every document contributes to the final output.\n",
    "  - **Logical Continuity**: The approach allows the response to grow and evolve logically, building on the context from previous documents.\n",
    "\n",
    "- **Cons**:\n",
    "  - **Sequential Processing**: It cannot be easily parallelized, as each step depends on the previous one.\n",
    "  - **Time-Consuming**: The iterative refinement process can be slower, especially when dealing with a large number of documents.\n",
    "\n",
    "- **Best Use Cases**:\n",
    "  - Long-form question answering where each document contributes additional details to the overall answer.\n",
    "  - Cases where maintaining a logical, evolving context is crucial.\n",
    "\n",
    "## 3. Map-Rerank\n",
    "The `map-rerank` approach is similar to `map-reduce` but with a focus on ranking rather than merging the responses.\n",
    "\n",
    "- **How It Works**:\n",
    "  - **Map Phase**: Each document is processed independently to generate a response.\n",
    "  - **Rerank Phase**: Each response is then scored based on its relevance or quality, and the highest-ranked response is selected.\n",
    "\n",
    "- **Pros**:\n",
    "  - **Relevance Focus**: Produces the most relevant response by selecting the highest-scoring result.\n",
    "  - **Efficiency**: Avoids aggregating diverse answers, simplifying the final output.\n",
    "\n",
    "- **Cons**:\n",
    "  - **Loss of Potentially Useful Context**: Some information from lower-ranked responses might be ignored, leading to loss of context.\n",
    "  - **Ranking Quality Dependence**: The final outcome depends on how effectively the responses are scored and ranked.\n",
    "\n",
    "- **Best Use Cases**:\n",
    "  - Retrieval-based tasks where a single, best answer is needed.\n",
    "  - Scenarios where focusing on the most relevant information is more important than combining all responses.\n",
    "\n",
    "## 4. Stuff\n",
    "The `stuff` approach is the simplest chain type that directly concatenates all the documents and feeds them to the model in a single pass.\n",
    "\n",
    "- **How It Works**:\n",
    "  - All the documents are concatenated to form one large input that is then fed to the model for a single summarization or answer generation.\n",
    "\n",
    "- **Pros**:\n",
    "  - **Full Context**: Since all the documents are concatenated, the model gets access to the entire context at once.\n",
    "  - **Simplicity**: Very straightforward and easy to implement.\n",
    "\n",
    "- **Cons**:\n",
    "  - **Token Limit Constraints**: The model has a token limit, which means it can only handle a small number of documents at a time if they are large.\n",
    "  - **Scalability Issues**: It is not suitable for large-scale document processing because of token size limitations.\n",
    "\n",
    "- **Best Use Cases**:\n",
    "  - Summarizing a few short documents that can easily fit into the modelâ€™s token limit.\n",
    "  - Cases where the complete context from all documents is important for the final answer.\n",
    "\n",
    "## Summary of Chain Types\n",
    "\n",
    "| Chain Type      | How It Works                      | Pros                                    | Cons                                     | Best Use Cases                         |\n",
    "|-----------------|-----------------------------------|-----------------------------------------|------------------------------------------|----------------------------------------|\n",
    "| **Map-Reduce**  | Independent summaries then merged | **Scalable**, **Parallelizable**        | **Context Loss**, **Complex Reduction**  | Summarizing large datasets, Q&A        |\n",
    "| **Refine**      | Iterative refinement of the answer | **Comprehensive**, **Context Continuity** | **Sequential**, **Slow**                 | Long-form Q&A, Building iterative context |\n",
    "| **Map-Rerank**  | Independent responses, then ranked | **Focus on Relevance**, **Efficient**   | **Potential Context Loss**               | Best-answer retrieval                  |\n",
    "| **Stuff**       | Concatenates all docs, single pass | **Full Context**, **Simple**            | **Token Limit**, **Not Scalable**        | Summarizing few short docs, Full context required |\n",
    "\n",
    "## Choosing the Right Chain Type\n",
    "- **If you have many documents and need an overview**: Use **Map-Reduce**. It is efficient for summarizing multiple documents independently and then combining them.\n",
    "- **If you need to iteratively build on context from each document**: Choose **Refine**. It helps in scenarios where logical evolution of the answer is required, providing a comprehensive view by iteratively refining the output.\n",
    "- **If relevance is the primary factor**: **Map-Rerank** is ideal when you need the single most relevant response from multiple documents. It helps in picking the top-quality content efficiently.\n",
    "- **If the number of documents is small, and all content needs to be considered together**: Use **Stuff**. It is useful when you can fit all documents into a single prompt, ensuring the full context is considered.\n",
    "\n",
    "## Combining Chain Types\n",
    "- **For Maximum Comprehensiveness**: Combine `Map-Reduce` with `Refine` for cases where you need both a broad overview and an iterative improvement to achieve depth.\n",
    "- **For Relevance and Context**: Use `Map-Rerank` to select the most relevant content, then use `Refine` to enhance and build upon it for a coherent output.\n",
    "\n",
    "Each chain type has strengths that align with different document processing needs, so understanding these differences can help in selecting the best chain for a specific use case or combining them effectively for maximum benefit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/lib/python3.11/site-packages (0.3.7)\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/lib/python3.11/site-packages (0.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.3.15)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (0.1.142)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (1.25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /opt/homebrew/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/lib/python3.11/site-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/homebrew/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kjevaji/Library/Python/3.11/lib/python/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  youtube-transcript-api\n",
    "%pip install --upgrade --quiet  pytube\n",
    "\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=BqbIRiYXd3U\", add_video_info=False\n",
    ")\n",
    "# load the youtube video caption into Documents\n",
    "docs = loader.load()\n",
    "# check how many characters in the doc and some content\n",
    "len(docs[0].page_content), docs[0].page_content[:300], len(docs)\n",
    "text = docs[0].page_content\n",
    "summary = llm.invoke(f\"Give me a summary of the text below: {text}.\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 1, 4655, 88209)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# create splits from content\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "# check length\n",
    "len(split_docs), len(docs), len(split_docs[0].page_content), len(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bv/01rc_d8n7tdgkwp7g9bvp4p40000gn/T/ipykernel_3596/1726956926.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  refineResult = chain.run(split_docs)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
    "refineResult = chain.run(split_docs)\n",
    "summaries = []\n",
    "summaries.append(refineResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "stuffResult = chain.run(split_docs)\n",
    "summaries.append(stuffResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3039 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "## shorter summary\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\") # another option is map-rerank\n",
    "map_reduceResult = chain.run(split_docs)\n",
    "summaries.append(map_reduceResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Got unsupported chain type: map_rerank. Should be one of dict_keys(['stuff', 'map_reduce', 'refine'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m## shorter summary\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m chain \u001b[39m=\u001b[39m load_summarize_chain(llm, chain_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmap_rerank\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39m# another option is map-rerank\u001b[39;00m\n\u001b[1;32m      3\u001b[0m map_reduceResult \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39mrun(split_docs)\n\u001b[1;32m      4\u001b[0m summaries\u001b[39m.\u001b[39mappend(map_reduceResult)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/langchain/chains/summarize/chain.py:163\u001b[0m, in \u001b[0;36mload_summarize_chain\u001b[0;34m(llm, chain_type, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m loader_mapping: Mapping[\u001b[39mstr\u001b[39m, LoadingCallable] \u001b[39m=\u001b[39m {\n\u001b[1;32m    158\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstuff\u001b[39m\u001b[39m\"\u001b[39m: _load_stuff_chain,\n\u001b[1;32m    159\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmap_reduce\u001b[39m\u001b[39m\"\u001b[39m: _load_map_reduce_chain,\n\u001b[1;32m    160\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrefine\u001b[39m\u001b[39m\"\u001b[39m: _load_refine_chain,\n\u001b[1;32m    161\u001b[0m }\n\u001b[1;32m    162\u001b[0m \u001b[39mif\u001b[39;00m chain_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loader_mapping:\n\u001b[0;32m--> 163\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    164\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unsupported chain type: \u001b[39m\u001b[39m{\u001b[39;00mchain_type\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShould be one of \u001b[39m\u001b[39m{\u001b[39;00mloader_mapping\u001b[39m.\u001b[39mkeys()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     )\n\u001b[1;32m    167\u001b[0m \u001b[39mreturn\u001b[39;00m loader_mapping[chain_type](llm, verbose\u001b[39m=\u001b[39mverbose, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: Got unsupported chain type: map_rerank. Should be one of dict_keys(['stuff', 'map_reduce', 'refine'])"
     ]
    }
   ],
   "source": [
    "## shorter summary\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_rerank\") # another option is map-rerank\n",
    "map_reduceResult = chain.run(split_docs)\n",
    "summaries.append(map_reduceResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl;dr generator\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# for summary in summaries:\n",
    "#     with open(f'temp_texts{summary[0]}.txt', 'w') as f:\n",
    "\n",
    "\n",
    "with open('temp_texts.txt', 'w') as f:\n",
    "    for summary in summaries:\n",
    "        f.write(summary + '\\n')\n",
    "\n",
    "text_loader = TextLoader('temp_texts.txt')\n",
    "summary_docs = text_loader.load();\n",
    "print(summary_docs)\n",
    "split_summaries = text_splitter.split_documents(summary_docs)\n",
    "\n",
    "final_chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "tldr = final_chain.run(split_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(refineResult)\n",
    "print(summaries)\n",
    "# print(docs)\n",
    "# len(tldr), len(refineResult), len(map_reduceResult)\n",
    "# print(tldr, refineResult, map_reduceResult)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
